#!/usr/bin/env python3
"""
Comprehensive QA Test for All Prompt Guide Questions
Tests if all questions return unique, specific responses rather than generic confirmations
"""

import requests
import json
import time
from typing import Dict, List, Tuple
from collections import defaultdict

# API endpoint
API_URL = "http://localhost:3000/api/ai/query"

# All prompt guide questions organized by category
PROMPT_QUESTIONS = {
    "Executive Summary & Overview": [
        "Give me an executive summary",
        "What is our overall performance?",
        "What are the key metrics?",
        "Show me a summary of our campaigns",
        "What is our performance overview?",
        "Give me a comprehensive summary"
    ],
    "Financial Performance": [
        "What is our total spend?",
        "What is our total revenue?",
        "What is our ROAS?",
        "What is our revenue?",
        "What is our CPA?",
        "What is our CPC?",
        "What is our CPM?",
        "What is our ROI?",
        "What is our profit margin?",
        "What is our CTR?",
        "What is our total spend?",
        "What is our total revenue?"
    ],
    "Platform Performance": [
        "How is Meta performing?",
        "What is DV360's performance?",
        "Show me Amazon's metrics",
        "What are SA360's results?",
        "How is TradeDesk performing?",
        "Which platform is doing the best?",
        "Compare platform performance",
        "What is the top performing platform?",
        "What is each platform's ROAS?",
        "How is Meta performing?",
        "What is DV360's performance?",
        "Show me Amazon's metrics"
    ],
    "Weekly Performance": [
        "How did we perform in week 1?",
        "Show me week 2 results",
        "What happened in week 3?",
        "How was week 4?",
        "Compare all weeks",
        "Which week performed best?",
        "What is our weekly trend?",
        "Show me week-by-week performance",
        "Which week had the highest ROAS?",
        "What was our best week?",
        "Show me weekly spend breakdown",
        "How did performance change week over week?"
    ],
    "Campaign Analysis": [
        "What is our best campaign?",
        "What is our top campaign?",
        "What is our worst campaign?",
        "Which campaign has the highest ROAS?",
        "Which campaigns should I pause?",
        "Show me campaign rankings",
        "Which campaigns are most efficient?",
        "Compare campaign performance",
        "What is the performance of each campaign?",
        "What is FreshNest Summer Grilling performance?",
        "What is our best campaign?",
        "What is our top campaign?"
    ],
    "Optimization Insights": [
        "What should we optimize?",
        "Give me optimization recommendations",
        "What can we improve?",
        "How can we improve performance?",
        "Where should we put more money?",
        "Give me strategic recommendations",
        "How can we increase ROAS?",
        "What should we optimize?",
        "What should we optimize?",
        "What should we optimize?",
        "What should we optimize?",
        "What should we optimize?"
    ],
    "Detailed Analytics": [
        "What is our click-through rate?",
        "How many conversions did we get?",
        "Show me audience performance",
        "How are our creatives performing?",
        "What is our CTR?",
        "What is our audience performance?",
        "What is our creative performance?",
        "What is our click-through rate?",
        "How many conversions did we get?",
        "Show me audience performance",
        "How are our creatives performing?",
        "What is our conversion rate?"
    ],
    "Creative & Audience": [
        "How did our creatives perform?",
        "Show me audience performance breakdown",
        "What creative optimizations should we make?",
        "Which audience segments performed best?",
        "What audience insights do you have?",
        "Which creative elements drove the most conversions?",
        "Show me creative performance by platform",
        "What audience targeting worked best?",
        "What creative recommendations do you have?",
        "How did our creatives perform?",
        "Show me audience performance",
        "How did our creatives perform?"
    ]
}

def test_query(query: str) -> Tuple[str, str, str]:
    """Test a single query and return status, response, and analysis"""
    
    payload = {
        "query": query,
        "sessionId": f"test_session_{int(time.time())}",
        "data": []  # The API will load sample data
    }
    
    try:
        response = requests.post(API_URL, json=payload, timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            content = result.get('content', '')
            
            # Analyze the response
            if not content or content.strip() == '':
                return "ERROR", content, "Empty response"
            
            # Check for generic responses
            generic_indicators = [
                "I understand you're asking about",
                "I can help you analyze your campaign data",
                "Try asking about",
                "â€¢ Platform performance",
                "â€¢ Campaign metrics",
                "â€¢ Financial metrics",
                "â€¢ Comparative analysis",
                "â€¢ Executive summary",
                "â€¢ Optimization insights"
            ]
            
            is_generic = any(indicator in content for indicator in generic_indicators)
            
            if is_generic:
                return "GENERIC", content, "Generic response detected"
            else:
                # Check if it's a specific response based on category
                category_indicators = {
                    "Executive Summary": ["executive", "summary", "overview", "key metrics", "performance", "ğŸ“Š", "ğŸ’°", "ğŸ’"],
                    "Financial": ["spend", "revenue", "roas", "cpa", "cpc", "cpm", "roi", "profit", "ğŸ’¸", "ğŸ’°", "ğŸ’µ", "ğŸ“ˆ"],
                    "Platform": ["meta", "dv360", "amazon", "sa360", "tradedesk", "platform", "ğŸ†", "ğŸ¥‡"],
                    "Weekly": ["week", "weekly", "trend", "breakdown", "ğŸ“…"],
                    "Campaign": ["campaign", "freshnest", "best", "worst", "ranking", "ğŸ¯", "ğŸ†", "ğŸ“‰"],
                    "Optimization": ["optimize", "improve", "opportunity", "recommendation", "strategy", "ğŸ’¡", "ğŸš€", "ğŸ”§"],
                    "Analytics": ["ctr", "conversion", "audience", "creative", "performance", "ğŸ“Š", "ğŸ¯", "ğŸ–±ï¸"],
                    "Creative": ["creative", "audience", "format", "segment", "targeting", "recommendation", "ğŸ¨", "ğŸ‘¥"]
                }
                
                # Determine which category this query belongs to
                query_lower = query.lower()
                matched_category = None
                for category, indicators in category_indicators.items():
                    if any(indicator in query_lower for indicator in indicators):
                        matched_category = category
                        break
                
                # Special handling for specific query patterns that are being misclassified
                if not matched_category:
                    if 'click-through rate' in query_lower or 'ctr' in query_lower:
                        matched_category = "Analytics"
                    elif 'creative formats' in query_lower or 'creative elements' in query_lower:
                        matched_category = "Creative"
                    elif 'put more money' in query_lower:
                        matched_category = "Optimization"
                
                if matched_category:
                    # Check if response has relevant content for that category
                    content_lower = content.lower()
                    has_relevant_content = any(indicator in content_lower for indicator in category_indicators[matched_category])
                    
                    # Additional checks for specific response types
                    if matched_category == "Financial":
                        # Check for financial metrics in response
                        financial_metrics = ["spend", "revenue", "roas", "cpa", "cpc", "roi", "profit", "ğŸ’¸", "ğŸ’°", "ğŸ’µ"]
                        has_relevant_content = has_relevant_content or any(metric in content_lower for metric in financial_metrics)
                    
                    elif matched_category == "Platform":
                        # Check for platform-specific content
                        platform_content = ["platform", "meta", "dv360", "amazon", "sa360", "tradedesk", "ğŸ†", "ğŸ¥‡"]
                        has_relevant_content = has_relevant_content or any(platform in content_lower for platform in platform_content)
                    
                    elif matched_category == "Campaign":
                        # Check for campaign-specific content
                        campaign_content = ["campaign", "freshnest", "best", "worst", "ranking", "ğŸ¯", "ğŸ†"]
                        has_relevant_content = has_relevant_content or any(campaign in content_lower for campaign in campaign_content)
                    
                    elif matched_category == "Optimization":
                        # Check for optimization-specific content
                        optimization_content = ["optimize", "improve", "opportunity", "recommendation", "strategy", "ğŸ’¡", "ğŸš€", "ğŸ”§"]
                        has_relevant_content = has_relevant_content or any(opt in content_lower for opt in optimization_content)
                    
                    elif matched_category == "Analytics":
                        # Check for analytics-specific content
                        analytics_content = ["ctr", "conversion", "audience", "creative", "performance", "ğŸ“Š", "ğŸ¯", "ğŸ–±ï¸"]
                        has_relevant_content = has_relevant_content or any(analytics in content_lower for analytics in analytics_content)
                    
                    elif matched_category == "Creative":
                        # Check for creative/audience-specific content
                        creative_content = ["creative", "audience", "format", "segment", "targeting", "recommendation", "ğŸ¨", "ğŸ‘¥"]
                        has_relevant_content = has_relevant_content or any(creative in content_lower for creative in creative_content)
                    
                    if has_relevant_content:
                        return "GOOD", content, f"Specific {matched_category} response"
                    else:
                        return "UNKNOWN", content, f"Response doesn't match {matched_category} indicators"
                else:
                    return "UNKNOWN", content, "Could not determine category"
                    
        else:
            return "ERROR", f"HTTP {response.status_code}", f"API error: {response.text}"
            
    except Exception as e:
        return "ERROR", str(e), f"Exception: {type(e).__name__}"

def analyze_response_uniqueness(responses: List[str]) -> Dict:
    """Analyze if responses are unique or repetitive"""
    
    # Normalize responses for comparison
    normalized_responses = []
    for resp in responses:
        # Remove common prefixes and normalize
        cleaned = resp.strip()
        # Remove emoji prefixes
        if cleaned.startswith("ğŸ¨") or cleaned.startswith("ğŸ“Š") or cleaned.startswith("ğŸ’°") or cleaned.startswith("ğŸ†") or cleaned.startswith("ğŸ¯") or cleaned.startswith("ğŸ’¡") or cleaned.startswith("ğŸ‘¥") or cleaned.startswith("ğŸ“ˆ"):
            cleaned = cleaned[1:].strip()
        # Remove common headers
        for header in ["EXECUTIVE SUMMARY", "FINANCIAL PERFORMANCE", "PLATFORM PERFORMANCE", "WEEKLY PERFORMANCE", "CAMPAIGN ANALYSIS", "OPTIMIZATION INSIGHTS", "DETAILED ANALYTICS", "CREATIVE", "AUDIENCE"]:
            if cleaned.upper().startswith(header):
                cleaned = cleaned[len(header):].strip()
        
        normalized_responses.append(cleaned.lower())
    
    # Count unique responses
    unique_responses = set(normalized_responses)
    uniqueness_ratio = len(unique_responses) / len(normalized_responses) if normalized_responses else 0
    
    # Find duplicates
    duplicates = []
    seen = {}
    for i, resp in enumerate(normalized_responses):
        if resp in seen:
            duplicates.append((seen[resp], i))
        else:
            seen[resp] = i
    
    return {
        "total_responses": len(responses),
        "unique_responses": len(unique_responses),
        "uniqueness_ratio": uniqueness_ratio,
        "duplicate_pairs": duplicates
    }

def main():
    print("ğŸ” COMPREHENSIVE UNIQUENESS QA TEST")
    print("=" * 60)
    print()
    
    all_results = {}
    all_responses = []
    
    for category, questions in PROMPT_QUESTIONS.items():
        print(f"ğŸ“‹ Testing Category: {category}")
        print("-" * 50)
        
        category_results = []
        category_responses = []
        
        for i, question in enumerate(questions, 1):
            print(f"  {i}. Testing: {question}")
            
            status, response, analysis = test_query(question)
            category_results.append({
                "question": question,
                "status": status,
                "response": response[:200] + "..." if len(response) > 200 else response,
                "analysis": analysis
            })
            category_responses.append(response)
            all_responses.append(response)
            
            print(f"      Status: {status}")
            print(f"      Analysis: {analysis}")
            print(f"      Response: {response[:100]}...")
            print()
            
            # Small delay between requests
            time.sleep(0.5)
        
        all_results[category] = category_results
        
        # Category summary
        status_counts = {}
        for result in category_results:
            status = result["status"]
            status_counts[status] = status_counts.get(status, 0) + 1
        
        print(f"ğŸ“Š {category} Summary:")
        for status, count in status_counts.items():
            print(f"  {status}: {count} ({count/len(category_results)*100:.1f}%)")
        print()
    
    # Overall uniqueness analysis
    uniqueness_analysis = analyze_response_uniqueness(all_responses)
    
    # Print comprehensive results
    print("ğŸ“Š COMPREHENSIVE QA RESULTS")
    print("=" * 60)
    
    total_questions = sum(len(questions) for questions in PROMPT_QUESTIONS.values())
    print(f"Total Questions Tested: {total_questions}")
    
    # Overall status counts
    overall_status_counts = defaultdict(int)
    for category_results in all_results.values():
        for result in category_results:
            overall_status_counts[result["status"]] += 1
    
    print("\nğŸ¯ OVERALL STATUS BREAKDOWN:")
    for status, count in overall_status_counts.items():
        print(f"  {status}: {count} ({count/total_questions*100:.1f}%)")
    
    print()
    print("ğŸ”„ RESPONSE UNIQUENESS ANALYSIS:")
    print(f"  Total Responses: {uniqueness_analysis['total_responses']}")
    print(f"  Unique Responses: {uniqueness_analysis['unique_responses']}")
    print(f"  Uniqueness Ratio: {uniqueness_analysis['uniqueness_ratio']:.2%}")
    
    if uniqueness_analysis['duplicate_pairs']:
        print(f"  Duplicate Response Pairs: {len(uniqueness_analysis['duplicate_pairs'])}")
        print("  Duplicate questions:")
        question_index = 0
        for category, questions in PROMPT_QUESTIONS.items():
            for i, question in enumerate(questions):
                for dup1, dup2 in uniqueness_analysis['duplicate_pairs']:
                    if dup1 == question_index or dup2 == question_index:
                        print(f"    - {category}: {question}")
                question_index += 1
    
    print()
    print("ğŸ“ˆ CATEGORY BREAKDOWN:")
    for category, results in all_results.items():
        status_counts = {}
        for result in results:
            status = result["status"]
            status_counts[status] = status_counts.get(status, 0) + 1
        
        print(f"\n{category}:")
        for status, count in status_counts.items():
            print(f"  {status}: {count} ({count/len(results)*100:.1f}%)")
    
    print()
    print("ğŸš¨ PROBLEMATIC QUESTIONS (Generic/Error/Unknown):")
    print("-" * 60)
    
    for category, results in all_results.items():
        problematic = [r for r in results if r["status"] in ["GENERIC", "ERROR", "UNKNOWN"]]
        if problematic:
            print(f"\n{category}:")
            for result in problematic:
                print(f"  âŒ {result['question']}")
                print(f"     Status: {result['status']}")
                print(f"     Analysis: {result['analysis']}")
                print(f"     Response: {result['response']}")
                print()
    
    # Save detailed results
    with open('qa_comprehensive_uniqueness_results.json', 'w') as f:
        json.dump({
            "summary": {
                "total_questions": total_questions,
                "overall_status_counts": dict(overall_status_counts),
                "uniqueness_analysis": uniqueness_analysis
            },
            "category_results": all_results
        }, f, indent=2)
    
    print(f"ğŸ’¾ Detailed results saved to: qa_comprehensive_uniqueness_results.json")

if __name__ == "__main__":
    main() 